{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy pandas seaborn ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "individual_household_electric_power_consumption = fetch_ucirepo(id=235)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "data = individual_household_electric_power_consumption.data.features\n",
    "\n",
    "# metadata\n",
    "print(individual_household_electric_power_consumption.metadata)\n",
    "\n",
    "# variable information\n",
    "print(individual_household_electric_power_consumption.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "data = data.set_index('datetime').sort_index()\n",
    "\n",
    "data.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "data = data[data['Global_active_power'] != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = data.index.to_numpy()\n",
    "gap = data['Global_active_power'].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(gap[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window_data(data, window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])  # The window of input data\n",
    "        y.append(data[i + window_size])    # The next value as the target\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_splits = 5\n",
    "window_size = 100\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(gap)):\n",
    "    #To get the indices\n",
    "    gap_train, gap_test = gap[train_index], gap[test_index]\n",
    "    X_train, y_train = create_sliding_window_data(gap_train, window_size)\n",
    "    X_test, y_test = create_sliding_window_data(gap_test, window_size)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(window_size, 1)))\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=50,\n",
    "        epochs=50,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    results = model.predict(X_test).reshape(-1)\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=1, nrows=2, constrained_layout=True, figsize=(20,5))\n",
    "    fig.suptitle(f'Fold {i+1}')\n",
    "    axs[0].set_title('Train Test Split')\n",
    "    axs[0].plot(datetimes[train_index], gap_train, c='blue', label='train')\n",
    "    axs[0].plot(datetimes[test_index], gap_test, c='orange', label='test')\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title('test result')\n",
    "    axs[1].plot(datetimes[test_index][window_size:], y_test, c='blue', label='ground truth')\n",
    "    axs[1].plot(datetimes[test_index][window_size:], results, c='orange', label='results')\n",
    "    axs[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train_oh,\n",
    "    batch_size=50,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, y_test_oh),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_df = pd.DataFrame(history.history)\n",
    "\n",
    "metrics = set([k.split('_')[-1] for k in history.history.keys()])\n",
    "\n",
    "fig, axs = plt.subplots(ncols=len(metrics), nrows=1, constrained_layout=True, figsize=(20,5))\n",
    "\n",
    "for plot_idx, metric in enumerate(metrics):\n",
    "    best = h_df.max(0) if metric != 'loss' else h_df.min(0)\n",
    "    axs[plot_idx].plot(\n",
    "        history.history[metric],\n",
    "        label=f'training (best={best[metric]:.3f})'\n",
    "    )\n",
    "    axs[plot_idx].plot(\n",
    "        history.history['val_'+metric],\n",
    "        label=f'validation (best={best[\"val_\"+metric]:.3f})'\n",
    "    )\n",
    "    axs[plot_idx].grid(True)\n",
    "    axs[plot_idx].set_title(metric)\n",
    "    axs[plot_idx].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(x_test)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_prediction, normalize=None)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='', cmap='Blues', ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
